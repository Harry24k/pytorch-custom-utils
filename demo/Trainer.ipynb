{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchhk.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded!\n",
      "Train Data Length : 60000\n",
      "Test Data Length : 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = Datasets(\"MNIST\", root='./data',\n",
    "                 transform_train=transforms.ToTensor(), \n",
    "                 transform_test=transforms.ToTensor())\n",
    "\n",
    "train_loader, _ = mnist.get_loader(batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CNN\n",
    "model = CNN().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchhk.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Important Attributes ###########################\n",
    "# self.model : model\n",
    "# self.device : device where model is\n",
    "# self.optimizer : optimizer\n",
    "# self.scheduler : scheduler (* Automatically Updated)\n",
    "# self.max_epoch : total number of epochs\n",
    "# self.max_iter : total number of iterations\n",
    "# self.epoch : current epoch (* Automatically Updated)\n",
    "# self.iter : current iter (* Automatically Updated)\n",
    "# self.record_keys : items to record == items returned by do_iter\n",
    "#########################################################################\n",
    "\n",
    "class BaseTrainer(Trainer):\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super(BaseTrainer, self).__init__(\"BaseTrainer\", model, **kwargs)\n",
    "        # Set Records (* Must be same as the items returned by do_iter)\n",
    "        self.record_keys = [\"Loss\", \"Acc\"]\n",
    "    \n",
    "    # Override Do Iter\n",
    "    def _do_iter(self, train_data):\n",
    "        images, labels = train_data\n",
    "        X = images.to(self.device)\n",
    "        Y = labels.to(self.device)\n",
    "\n",
    "        pre = self.model(X)\n",
    "        cost = nn.CrossEntropyLoss()(pre, Y)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        _, pre = torch.max(pre.data, 1)\n",
    "        total = pre.size(0)\n",
    "        correct = (pre == Y).sum()\n",
    "        cost = cost.item()\n",
    "        \n",
    "        return cost, 100*float(correct)/total\n",
    "    \n",
    "    # Override Update Scheduler\n",
    "    def _update_scheduler(self):\n",
    "        self.scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BaseTrainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BaseTrainer]\n",
      "Training Information.\n",
      "-Epochs: 4\n",
      "-Optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "-Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000001ACC93BC080>\n",
      "-Save Path: ./_models/\n",
      "-Save Type: Epoch\n",
      "-Record Type: Epoch\n",
      "-Device: cuda:0\n",
      "------------------------------------               \n",
      "Epoch   Loss     Acc       lr       \n",
      "====================================\n",
      "1       0.6329   79.6191   0.0100   \n",
      "------------------------------------\n",
      "2       0.0898   97.1738   0.0100                  \n",
      "------------------------------------\n",
      "3       0.0579   98.2255   0.0100                  \n",
      "------------------------------------\n",
      "4       0.0462   98.5260   0.0100                  \n",
      "------------------------------------\n",
      "====================================\n",
      "Total Epoch: 4\n",
      "Time Elapsed: 0:00:30.938809\n",
      "Min(epoch)/Max(epoch): \n",
      "-Loss: 0.0462(4)/0.6329(1)\n",
      "-Acc: 79.6191(1)/98.5260(4)\n",
      "-lr: 0.0100(1)/0.0100(1)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader=train_loader, max_epoch=4,\n",
    "              optimizer=\"SGD(lr=0.01, momentum=0.9)\",\n",
    "              scheduler=\"MultiStepLR(milestones=[4, 6], gamma=0.1)\", scheduler_type=\"Epoch\",\n",
    "              # Easy Scheduler String for the most used:\n",
    "              ## Step(milestones=[2, 4], gamma=0.1)\n",
    "              ## Cyclic(base_lr=0, max_lr=0.3)\n",
    "              ## Cosine\n",
    "              save_type=\"Epoch\", save_path=\"./_models/\", save_overwrite=False,\n",
    "              record_type=\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Save files will be overwritten!\n",
      "[BaseTrainer]\n",
      "Training Information.\n",
      "-Epochs: 8\n",
      "-Optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "-Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000001ACC93BC4A8>\n",
      "-Save Path: _models/\n",
      "-Save Type: Epoch\n",
      "-Record Type: Epoch\n",
      "-Device: cuda:0\n",
      "Progress: \\ [0:00:00.015596/it]                    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slcf\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:122: UserWarning:\n",
      "\n",
      "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------               \n",
      "Epoch   Loss     Acc       lr       \n",
      "====================================\n",
      "5       0.0272   99.1904   0.0010   \n",
      "------------------------------------\n",
      "6       0.0240   99.3005   0.0010                  \n",
      "------------------------------------\n",
      "7       0.0219   99.3840   0.0001                  \n",
      "------------------------------------\n",
      "8       0.0215   99.3857   0.0001                  \n",
      "------------------------------------\n",
      "====================================\n",
      "Total Epoch: 8\n",
      "Time Elapsed: 0:00:29.846119\n",
      "Min(epoch)/Max(epoch): \n",
      "-Loss: 0.0215(8)/0.0272(5)\n",
      "-Acc: 99.1904(5)/99.3857(8)\n",
      "-lr: 0.0001(7)/0.0010(5)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader=train_loader, max_epoch=8, start_epoch=4,\n",
    "              optimizer=\"SGD(lr=0.01, momentum=0.9)\",\n",
    "              scheduler=\"MultiStepLR(milestones=[4, 6], gamma=0.1)\", scheduler_type=\"Epoch\",\n",
    "              # or scheduler=\"Step([4, 6], 0.1)\"\n",
    "              save_type=\"Epoch\", save_path=\"_models/\", save_overwrite=True,\n",
    "              record_type=\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "...Saved as pth to final.pth !\n",
      "Saving Records\n",
      "...Saved as csv to final.csv !\n"
     ]
    }
   ],
   "source": [
    "trainer.save_all(\"final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
