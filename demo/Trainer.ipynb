{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchhk.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded!\n",
      "Train Data Length : 60000\n",
      "Test Data Length : 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = Datasets(\"MNIST\", root='./data',\n",
    "                 transform_train=transforms.ToTensor(), \n",
    "                 transform_test=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader, _ = mnist.get_loader(batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*3*3, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv_layer(x)\n",
    "        out = out.view(-1,64*3*3)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchhk.trainer import BaseTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().cuda()\n",
    "trainer = BaseTrainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BaseTrainer]\n",
      "Training Information.\n",
      "-Epochs: 4\n",
      "-Optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "-Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000001EFEA0DA6A0>\n",
      "-Save Path: ./_models/\n",
      "-Save Type: Epoch\n",
      "-Record Type: Epoch\n",
      "-Device: cuda:0\n",
      "------------------------------------              \n",
      "Epoch   Loss     Acc       lr       \n",
      "====================================\n",
      "1       0.5816   80.4270   0.0100   \n",
      "------------------------------------\n",
      "2       0.0829   97.4058   0.0100                 \n",
      "------------------------------------\n",
      "3       0.0541   98.2806   0.0100                 \n",
      "------------------------------------\n",
      "4       0.0426   98.6612   0.0100                 \n",
      "------------------------------------\n",
      "====================================\n",
      "Total Epoch: 4\n",
      "Time Elapsed: 0:00:30.279924\n",
      "Min(epoch)/Max(epoch): \n",
      "-Loss: 0.0426(4)/0.5816(1)\n",
      "-Acc: 80.4270(1)/98.6612(4)\n",
      "-lr: 0.0100(1)/0.0100(1)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader=train_loader, max_epoch=4,\n",
    "              optimizer=\"SGD(lr=0.01, momentum=0.9)\",\n",
    "              scheduler=\"MultiStepLR(milestones=[4, 6], gamma=0.1)\", scheduler_type=\"Epoch\",\n",
    "              # or scheduler=\"Step([2, 4], 0.1)\"\n",
    "              save_type=\"Epoch\", save_path=\"./_models/\", save_overwrite=False,\n",
    "              record_type=\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Save files will be overwritten!\n",
      "[BaseTrainer]\n",
      "Training Information.\n",
      "-Epochs: 8\n",
      "-Optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "-Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000001EFEA0B00F0>\n",
      "-Save Path: _models/\n",
      "-Save Type: Epoch\n",
      "-Record Type: Epoch\n",
      "-Device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slcf\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:122: UserWarning:\n",
      "\n",
      "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------              \n",
      "Epoch   Loss     Acc       lr       \n",
      "====================================\n",
      "5       0.0253   99.2772   0.0010   \n",
      "------------------------------------\n",
      "6       0.0229   99.3640   0.0010                 \n",
      "------------------------------------\n",
      "7       0.0213   99.4040   0.0001                 \n",
      "------------------------------------\n",
      "8       0.0209   99.4274   0.0001                 \n",
      "------------------------------------\n",
      "====================================\n",
      "Total Epoch: 8\n",
      "Time Elapsed: 0:00:29.144723\n",
      "Min(epoch)/Max(epoch): \n",
      "-Loss: 0.0209(8)/0.0253(5)\n",
      "-Acc: 99.2772(5)/99.4274(8)\n",
      "-lr: 0.0001(7)/0.0010(5)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader=train_loader, max_epoch=8, start_epoch=4,\n",
    "              optimizer=\"SGD(lr=0.01, momentum=0.9)\",\n",
    "              scheduler=\"MultiStepLR(milestones=[4, 6], gamma=0.1)\", scheduler_type=\"Epoch\",\n",
    "              # or scheduler=\"Step([2, 4], 0.1)\"\n",
    "              save_type=\"Epoch\", save_path=\"_models/\", save_overwrite=True,\n",
    "              record_type=\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "...Saved as pth to final.pth !\n",
      "Saving Records\n",
      "...Saved as csv to final.csv !\n"
     ]
    }
   ],
   "source": [
    "trainer.save_all(\"final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
